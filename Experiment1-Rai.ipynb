{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name: Umad ul hassan Rai\n",
    "# Exercise 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import concat, col, lit, split, udf, size\n",
    "from pyspark.sql import functions as sf\n",
    "from operator import add\n",
    "import csv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise Spark Session\n",
    "sparkSession = SparkSession.builder.appName(\"Exercise1\").getOrCreate()\n",
    "sc = sparkSession.sparkContext\n",
    "sqlC = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f05bcffe7951de9e5a32fff4a42eb088',\n",
       "  ['1158654',\n",
       "   '478707',\n",
       "   '12054725',\n",
       "   '6670515',\n",
       "   '781057',\n",
       "   '13329754',\n",
       "   '781055',\n",
       "   '2825',\n",
       "   '553840',\n",
       "   '988447',\n",
       "   '12938139',\n",
       "   '12037219',\n",
       "   '12788583',\n",
       "   '6595566',\n",
       "   '4027225',\n",
       "   '920055',\n",
       "   '3129258',\n",
       "   '2242776',\n",
       "   '3112352',\n",
       "   '144287',\n",
       "   '706033',\n",
       "   '525396',\n",
       "   '622633',\n",
       "   '9172127',\n",
       "   '7357993',\n",
       "   '230211',\n",
       "   '12790816',\n",
       "   '503161',\n",
       "   '12937120',\n",
       "   '942241',\n",
       "   '166220',\n",
       "   '8493138',\n",
       "   '2945819',\n",
       "   '227173',\n",
       "   '11191048',\n",
       "   '949352',\n",
       "   '227096',\n",
       "   '11597926',\n",
       "   '921623',\n",
       "   '833638',\n",
       "   '882809',\n",
       "   '12738996',\n",
       "   '99',\n",
       "   '7154210',\n",
       "   '11852474',\n",
       "   '72879',\n",
       "   '10723139',\n",
       "   '11923443',\n",
       "   '2862386',\n",
       "   '802634',\n",
       "   '1959297',\n",
       "   '4488840',\n",
       "   '12735311',\n",
       "   '5102465',\n",
       "   '5177766',\n",
       "   '129',\n",
       "   '1467354',\n",
       "   '9396734',\n",
       "   '494336',\n",
       "   '1218954',\n",
       "   '2783692',\n",
       "   '3733678',\n",
       "   '8423325',\n",
       "   '1160828',\n",
       "   '507529',\n",
       "   '7804574',\n",
       "   '5201306',\n",
       "   '407124',\n",
       "   '504896',\n",
       "   '3281478',\n",
       "   '13687046',\n",
       "   '6486855',\n",
       "   '13207613',\n",
       "   '11847579',\n",
       "   '556147',\n",
       "   '10362464',\n",
       "   '6531882',\n",
       "   '714977',\n",
       "   '9946377',\n",
       "   '742892',\n",
       "   '3044720',\n",
       "   '1119267',\n",
       "   '7538620',\n",
       "   '1426283',\n",
       "   '2705980',\n",
       "   '9001253',\n",
       "   '2121165',\n",
       "   '12901647',\n",
       "   '10462916',\n",
       "   '261290',\n",
       "   '921399',\n",
       "   '6196237',\n",
       "   '5664256',\n",
       "   '213068',\n",
       "   '1769635',\n",
       "   '1055600',\n",
       "   '876703',\n",
       "   '7623038',\n",
       "   '1405472',\n",
       "   '1320137',\n",
       "   '4492925',\n",
       "   '1825619',\n",
       "   '13408130',\n",
       "   '1320157',\n",
       "   '682116',\n",
       "   '405672',\n",
       "   '1814546',\n",
       "   '12732269',\n",
       "   '12394780',\n",
       "   '1835552',\n",
       "   '9445526',\n",
       "   '80543',\n",
       "   '5413529',\n",
       "   '1153421',\n",
       "   '12925513',\n",
       "   '1784935',\n",
       "   '10802130',\n",
       "   '6305290',\n",
       "   '3856997',\n",
       "   '2097471',\n",
       "   '3748163',\n",
       "   '12796779',\n",
       "   '878326',\n",
       "   '10098153',\n",
       "   '3459771',\n",
       "   '827938',\n",
       "   '4448813',\n",
       "   '239',\n",
       "   '9478785',\n",
       "   '579614',\n",
       "   '7355647',\n",
       "   '423698',\n",
       "   '556149',\n",
       "   '13329593',\n",
       "   '9081047',\n",
       "   '151946',\n",
       "   '1453872',\n",
       "   '671699',\n",
       "   '3578102',\n",
       "   '137486',\n",
       "   '703464',\n",
       "   '9069826',\n",
       "   '622635',\n",
       "   '6792520',\n",
       "   '247',\n",
       "   '12716731',\n",
       "   '10045309',\n",
       "   '255030',\n",
       "   '968854',\n",
       "   '3726797',\n",
       "   '8217163',\n",
       "   '2945839',\n",
       "   '11839662',\n",
       "   '10685085',\n",
       "   '2308256',\n",
       "   '9983047',\n",
       "   '10138849',\n",
       "   '11536389',\n",
       "   '945310',\n",
       "   '1036492',\n",
       "   '6982661',\n",
       "   '1649749',\n",
       "   '1325105',\n",
       "   '6475030',\n",
       "   '488726',\n",
       "   '100186',\n",
       "   '3317637',\n",
       "   '336911',\n",
       "   '1321106',\n",
       "   '3956160'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have measure time for exercise 1.3 which i have put in comments\n",
    "# Top 10 word count took around 46 mintues to complete \n",
    "\n",
    "# Creating userRating RDD from users_libraries.\n",
    "rdd1 = sparkSession.sparkContext.textFile(\"users_libraries.txt\")\n",
    "userRatingsRDD = rdd1.map(lambda x: (x.split(';')[0], x.split(';')[1].split(',')))\n",
    "\n",
    "# Extracting key/value pair from key/values(list) so i can join\n",
    "exploded = userRatingsRDD.flatMap(lambda l: [(l[0], value) for value in l[1]])\n",
    "\n",
    "#Reversing rdd to paper_id/User to perform join on papersTermRdd\n",
    "reversed_ = exploded.map(lambda x: (x[1],x[0]))\n",
    "\n",
    "userRatingsRDD.take(1)\n",
    "#reversed_.take(10)\n",
    "#exploded.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('80546',\n",
       "  \"the genetic code has been regarded as arbitrary in the sense that the codon-amino acid assignments could be different than they actually are. this general idea has been spelled out differently by previous, often rather implicit accounts of arbitrariness. they have drawn on the frozen accident theory, on evolutionary contingency, on alternative causal pathways, and on the absence of direct stereochemical interactions between codons and amino acids. it has also been suggested that the arbitrariness of the genetic code justifies attributing semantic information to macromolecules, notably to {dna}. i argue that these accounts of arbitrariness are unsatisfactory. i propose that the code is arbitrary in the sense of jacques monod's concept of chemical arbitrariness: the genetic code is arbitrary in that any codon requires certain chemical and structural properties to specify a particular amino acid, but these properties are not required in virtue of a principle of chemistry. this notion of arbitrariness is compatible with several recent hypotheses about code evolution. i maintain that the code's chemical arbitrariness is neither sufficient nor necessary for attributing semantic information to nucleic acids.\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using csv to parse the papers.CSV file to map paper id and abstract as Key/Value\n",
    "# Also allows to replace null bytes in csv file.\n",
    "# Creating paperTermsRDD\n",
    "rdd2 = sparkSession.sparkContext.textFile(\"papers.csv\")\n",
    "paperTermsRDD = rdd2.map(lambda line: next(csv.reader(x.replace(\"\\x00\", \"\") for x in [line]))) \\\n",
    "                    .map(lambda fields: (fields[0], fields[14]))\n",
    "paperTermsRDD.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BroadCasting StopWords\n",
    "# Timer\n",
    "start = time.time()\n",
    "data = [word.rstrip() for word in open(\"stopwords_en.txt\", 'r').readlines()]\n",
    "broadcastVar = sc.broadcast(data)\n",
    "# broadcastVar.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joined UserRatingsRDD(Reversed) with PaperTermsRDD\n",
    "joinedRDD = reversed_.join(paperTermsRDD)\n",
    "\n",
    "# joinedRDD.take(20)\n",
    "\n",
    "user_abs = joinedRDD.map(lambda x: (x[1][0], x[1][1]))\n",
    "\n",
    "# user_abs.take(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reduced by key before counting words for each user.\n",
    "grouped = user_abs.reduceByKey(lambda x,y: x + y)\n",
    "grouped.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8123c9baf50aa777ed3211b5b6306bd0',\n",
       "  'meme is a tool for discovering motifs in sets of protein or dna sequences this paper describes several extensions to meme which increase its ability to find motifs in a totally unsupervised fashion but which also allow it to benefit when prior knowledge is available when no background knowledge is asserted meme obtains increased robustness from a method for determining motif widths automatically and from probabilistic models that allow motifs to be absent in some input sequences on the other hand meme can exploit prior knowledge about a motif being present in all input sequences about the length of a motif and whether it is a palindrome and using dirichlet mixtures about expected patterns in individual motif positions extensive experiments are reported which support the claim that meme benefits from but does not require background knowledge the experiments use seven previously studied dna and protein sequence families and 75 of the protein families documented in the prosite database of sites and patterns release 111systematic mapping of protein–protein interactions or interactome mapping was initiated in model organisms starting with defined biological processes1 2 and then expanding to the scale of the proteome3 4 5 6 7 although far from complete such maps have revealed global topological and dynamic features of interactome networks that relate to known biological properties8 9 suggesting that a human interactome map will provide insight into development and disease mechanisms at a systems level here we describe an initial version of a proteomescale map of human binary protein–protein interactions using a stringent highthroughput yeast twohybrid system we tested pairwise interactions among the products of 8100 currently available gatewaycloned open reading frames and detected 2800 interactions this data set called ccsbhi1 has a verification rate of 78 as revealed by an independent coaffinity purification assay and correlates significantly with other biological attributes the ccsbhi1 data set increases by 70 the set of available binary interactions within the tested space and reveals more than 300 new connections to over 100 diseaseassociated proteins this work represents an important step towards a systematic and comprehensive human interactome projectoligonucleotide and complementary dna microarrays are being used to subclassify histologically similar tumours monitor disease progress and individualize treatment regimens1 2 3 4 5 however extracting new biological insight from highthroughput genomic studies of human diseases is a challenge limited by difficulties in recognizing and evaluating relevant biological processes from huge quantities of experimental data here we present a structured network knowledgebase approach to analyse genomewide transcriptional responses in the context of known functional interrelationships among proteins small molecules and phenotypes this approach was used to analyse changes in blood leukocyte gene expression patterns in human subjects receiving an inflammatory stimulus bacterial endotoxin we explore the known genomewide interaction network to identify significant functional modules perturbed in response to this stimulus our analysis reveals that the human blood leukocyte response to acute systemic inflammation includes the transient dysregulation of leukocyte bioenergetics and modulation of translational machinery these findings provide insight into the regulation of global leukocyte activities as they relate to innate immune system tolerance and increased susceptibility to infection in humansprotein complexes are key molecular entities that integrate multiple gene products to perform cellular functions here we report the first genomewide screen for complexes in an organism budding yeast using affinity purification and mass spectrometry through systematic tagging of open reading frames orfs the majority of complexes were purified several times suggesting screen saturation the richness of the data set enabled a de novo characterization of the composition and organization of the cellular machinery the ensemble of cellular proteins partitions into 491 complexes of which 257 are novel that differentially combine with additional attachment proteins or protein modules to enable a diversification of potential functions support for this modular organization of the proteome comes from integration with available data on expression localization function evolutionary conservation protein structure and binary interactions this study provides the largest collection of physically determined eukaryotic cellular machines so far and a platform for biological data integration and modellingthe role of small rnas as key regulators of mrna turnover and translation has been well established recent advances indicate that the small rnas termed micrornas play important roles in animal development and physiology cellular activities such as proliferation morphogenesis apoptosis and differentiation are regulated by micrornas the expression of various genes are regulated by micrornas and several micrornas act in reciprocal negative feedback loops with protein factors to control cell fate decisions that are triggered by signal transduction activity these observations implicate small rnas as important mediators of gene regulation in response to cellcell signaling the mechanism by which micrornas silence gene expression is posttranscriptional possibly influencing the stability compartmentalization and translation of mrnas this mechanism is an efficient means to regulate production of a diverse range of proteinswe describe a systematic genomewide approach for learning the complex combinatorial code underlying gene expression our probabilistic approach identifies local dnasequence elements and the positional and combinatorial constraints that determine their contextdependent role in transcriptional regulation the inferred regulatory rules correctly predict expression patterns for 73 of genes in saccharomyces cerevisiae utilizing microarray expression data and sequences in the 800 bp upstream of genes application to caenorhabditis elegans identifies predictive regulatory elements and combinatorial rules that control the phased temporal expression of transcription factors histones and germline specific genes successful prediction requires diverse and complex rules utilizing and or and not logic with significant constraints on motif strength orientation and relative position this system generates a large number of mechanistic hypotheses for focused experimental validation and establishes a predictive dynamical framework for understanding cellular behavior from genomic sequencethe exploration of quantitative variation in human populations has become one of the major priorities for medical genetics the successful identification of variants that contribute to complex traits is highly dependent on reliable assays and genetic maps we have performed a genomewide quantitative trait analysis of 630 genes in 60 unrelated utah residents with ancestry from northern and western europe using the publicly available phase i data of the international hapmap project the genes are located in regions of the human genome with elevated functional annotation and disease interest including the encode regions spanning 1 of the genome chromosome 21 and chromosome 20q12–132 we apply three different methods of multiple test correction including bonferroni false discovery rate and permutations for the 374 expressed genes we find many regions with statistically significant association of single nucleotide polymorphisms snps with expression variation in lymphoblastoid cell lines after correcting for multiple tests based on our analyses the signal proximal cis to the genes of interest is more abundant and more stable than distal and trans across statistical methodologies our results suggest that regulatory polymorphism is widespread in the human genome and show that the 5kb phase i hapmap has sufficient density to enable linkage disequilibrium mapping in humans such studies will significantly enhance our ability to annotate the noncoding part of the genome and interpret functional variation in addition we demonstrate that the hapmap cell lines themselves may serve as a useful resource for quantitative measurements at the cellular level with the finished reference sequence of the human genome now available focus has shifted towards trying to identify all of the functional elements within the sequence although quite a lot of progress has been made towards identifying some classes of genomic elements in particular proteincoding sequences the characterization of regulatory elements remains a challenge the authors describe the genetic mapping of regions of the genome that have functional effects on quantitative levels of gene expression gene expression of 630 genes was measured in cell lines derived from 60 unrelated human individuals the same utah residents of northern and western european ancestry that have been genetically wellcharacterized by the international hapmap project this paper reports significant variation among individuals with respect to levels of gene expression and demonstrates that this quantitative trait has a genetic basis for some genes the genetic signal was localized to specific locations in the human genome sequence in most cases the genomic region associated with expression variation was physically close to the gene whose expression it regulated the authors demonstrate the feasibility of performing wholegenome association scans to map quantitative traits and highlight statistical issues that are increasingly important for wholegenome disease mapping studiesthe synthesis of gene expression data and cis regulatory analysis permits the elucidation of genomic regulatory networks these networks provide a direct visualization of the functional interconnections among the regulatory genes and signaling components leading to cellspecific patterns of gene activity complex developmental processes are thereby illuminated in ways not revealed by the conventional analysis of individual genes in this review we describe emerging networks in several different model systems and compare them with the gene regulatory network that controls dorsoventral patterning of the drosophila embryowe propose a modeldriven approach for analyzing genomic expression data that permits genetic regulatory networks to be represented in a biologically interpretable computational form our models permit latent variables capturing unobserved factors describe arbitrarily complex more than pairwise relationships at varying levels of refinement and can be scored rigorously against observational data the models that we use are based on bayesian networks and their extensions as a demonstration of this approach we utilize 52 genomes worth of affymetrix genechip expression data to correctly differentiate between alternative hypotheses of the galactose regulatory network in s cerevisiae when we extend the graph semantics to permit annotated edges we are able to score models describing relationships at a finer degree of specificationwe develop a new framework for inferring models of transcriptional regulation the models which we call physical network models are annotated molecular interaction graphs the attributes in the model correspond to verifiable properties of the underlying biological system such as the existence of proteinprotein and proteindna interactions the directionality of signal transduction in proteinprotein interactions as well as signs of the immediate effects of these interactions possible configurations of these variables are constrained by the available data sources some of the data sources such as factorbinding data involve measurements that are directly tied to the variables in the model other sources such as gene knockouts are functional in nature and provide only indirect evidence about the variables we associate each observed knockout effect in the deletion mutant data with a set of causal paths molecular cascades that could in principle explain the effect resulting in aggregate constraints about the physical variables in the model the most likely settings of all the variables specifying the most likely graph annotations are found by a recursive application of the maxproduct algorithm by testing our approach on datasets related to the pheromone response pathway in s cerevisiae we demonstrate that the resulting model is consistent with previous studies about the pathway moreover we successfully predict gene knockout effects with a high degree of accuracy in a crossvalidation setting when applying this approach genomewide we extract submodels consistent with previous studies the approach can be readily extended to other data sources or to facilitate automated experimental designas genomescale measurements lead to increasingly complex models of gene regulation systematic approaches are needed to validate and refine these models towards this goal we describe an automated procedure for prioritizing genetic perturbations in order to discriminate optimally between alternative models of a generegulatory network using this procedure we evaluate 38 candidate regulatory networks in yeast and perform four highpriority gene knockout experiments the refined networks support previously unknown regulatory mechanisms downstream of sok2 and swi4background the study of complex biological networks and prediction of gene function has been enabled by highthroughput htp methods for detection of genetic and protein interactions sparse coverage in htp datasets may however distort network properties and confound predictions although a vast number of well substantiated interactions are recorded in the scientific literature these data have not yet been distilled into networks that enable systemlevel inference results we describe here a comprehensive database of genetic and protein interactions and associated experimental evidence for the budding yeast saccharomyces cerevisiae as manually curated from over 31793 abstracts and online publications this literaturecurated lc dataset contains 33311 interactions on the order of all extant htp datasets combined surprisingly htp proteininteraction datasets currently achieve only around 14 coverage of the interactions in the literature the lc network nevertheless shares attributes with htp networks including scalefree connectivity and correlations between interactions abundance localization and expression we find that essential genes or proteins are enriched for interactions with other essential genes or proteins suggesting that the global network may be functionally unified this interconnectivity is supported by a substantial overlap of protein and genetic interactions in the lc dataset we show that the lc dataset considerably improves the predictive power of networkanalysis approaches the full lc dataset is available at the biogrid httpwwwthebiogridorg and sgd httpwwwyeastgenomeorg databases conclusion comprehensive datasets of biological interactions derived from the primary literature provide critical benchmarks for htp methods augment functional prediction and reveal systemlevel attributes of biological networksin this paper we describe an approach for identifying pathways from gene expression and protein interaction data our approach is based on the assumption that many pathways exhibit two properties their genes exhibit a similar gene expression profile and the protein products of the genes often interact  our approach is based on a unified probabilistic model which is learned from the data using the em algorithm we present results on two saccharomyces cerevisiae gene expression data sets combined with a binary protein interaction data set our results show that our approach is much more successful than other approaches at discovering both coherent functional groups and entire protein complexescontact erancsstanfordedukeywords probabilistic models protein interaction gene expressionwe propose a statistical method to estimate gene networks from dna microarray data and proteinprotein interactions because physical interactions between proteins or multiprotein complexes are likely to regulate biological processes using only mrna expression data is not sufficient for estimating a gene network accurately our method adds knowledge about proteinprotein interactions to the estimation method of gene networks under a bayesian statistical framework in the estimated gene network a protein complex is modeled as a virtual node based on principal component analysis we show the effectiveness of the proposed method through the analysis of saccharomyces cerevisiae cell cycle data the proposed method improves the accuracy of the estimated gene networks and successfully identifies some biological factsthe prediction of regulatory elements is a problem where computational methods offer great hope over the past few years numerous tools have become available for this task the purpose of the current assessment is twofold to provide some guidance to users regarding the accuracy of currently available tools in various settings and to provide a benchmark of data sets for assessing future toolswe develop principled methods for the automatic induction discovery of genetic regulatory network models from multiple data sources and data modalities models of regulatory networks are represented as bayesian networks allowing the models to compactly and robustly capture probabilistic multivariate statistical dependencies between the various cellular factors in these networks we build on previous bayesian network validation results by extending the validation framework to the context of model induction leveraging heuristic simulated annealing search algorithms and posterior model averaging using expression data in isolation yields results inconsistent with location data so we incorporate genomic location data to guide the model induction process we combine these two data modalities by allowing location data to influence the model prior and expression data to influence the model likelihood we demonstrate the utility of this approach by discovering genetic regulatory models of thirtythree variables involved in s cerevisiae pheromone response the models we automatically generate are consistent with the current understanding regarding this regulatory network but also suggest new directions for future experimental investigationciona is an emerging model system for elucidating gene networks in development comprehensive in situ hybridization assays have identified 76 regulatory genes with localized expression patterns in the early embryo at the time when naive blastomeres are determined to follow specific cell fates systematic gene disruption assays provided more than 3000 combinations of gene expression profiles in mutant backgrounds deduced gene circuit diagrams describing the formation of larval tissues were computationally visualized these diagrams constitute a blueprint for the ciona embryo and provide a foundation for understanding the evolutionary origins of the chordate body plan 101126science1123404genomewide transcript profiling was used to monitor signal transduction during yeast pheromone response genetic manipulations allowed analysis of changes in gene expression underlying pheromone signaling cell cycle control and polarized morphogenesis a twodimensional hierarchical clustered matrix covering 383 of the most highly regulated genes was constructed from 46 diverse experimental conditions diagnostic subsets of coexpressed genes reflected signaling activity cross talk and overlap of multiple mitogenactivated protein kinase mapk pathways analysis of the profiles specified by two different mapksfus3p and kss1prevealed functional overlap of the filamentous growth and mating responses global transcript analysis reflects biological responses associated with the activation and perturbation of signal transduction pathwayswe present a probabilistic framework that models the process by which transcriptional binding explains the mrna expression of different genes our joint probabilistic model unifies the two key components of this process the prediction of gene regulation events from sequence motifs in the genes promoter region and the prediction of mrna expression from combinations of gene regulation events in different settings our approach has several advantages by learning promoter sequence motifs thatwe propose a probabilistic model for cellular processes and an algorithm for discovering them from gene expression data a process is associated with a set of genes that participate in it unlike clustering techniques our model allows genes to participate in multiple processes each process may be active to a different degree in each experiment the expression measurement for gene g in array a is a sum over all processes in which g participates of the activity levels of these processes in array a we describe an iterative procedure based on the em algorithm for decomposing the expression matrix into a given number of processes we present results on yeast gene expression data which indicate that our approach identifies real biological processesmotivation in model organisms such as yeast large databases of protein–protein and proteindna interactions have become an extremely important resource for the study of protein function evolution and gene regulatory dynamics in this paper we demonstrate that by integrating these interactions with widelyavailable mrna expression data it is possible to generate concrete hypotheses for the underlying mechanisms governing the observed changes in gene expression to perform this integration systematically and at large scale we introduce an approach for screening a molecular interaction network to identify active subnetworks ie connected regions of the network that show significant changes in expression over particular subsets of conditions the method we present here combines a rigorous statistical measure for scoring subnetworks with a search algorithm for identifying subnetworks with high scorethe modeling of cellular signaling pathways is an emerging field sachs et al illustrate the application of bayesian networks to an example cellular pathway involving the activation of focal adhesion kinase fak and extracellular signalregulated kinase erk in response to fibronectin binding to an integrin they describe how to use the analysis to select from among proposed models formulate hypotheses regarding component interactions and uncover potential dynamic changes in the interactions between these components although the data sets currently available for this example problem are too small to definitively point to a particular model the approach and results provide a glimpse into the power that these methods will achieve once the technology for obtaining the necessary data becomes readily availablemotivation biological processes in cells are properly performed by gene regulations signal transductions and interactions between proteins to understand such molecular networks we propose a statistical method to estimate gene regulatory networks and proteinprotein interaction networks simultaneously from dna microarray data proteinprotein interaction data and other genomewide data results we unify bayesian networks and markov networks for estimating gene regulatory networks and proteinprotein interaction networks according to the reliability of each biological information source through the simultaneous construction of gene regulatory networks and proteinprotein interaction networks of saccharomyces cerevisiae cell cycle we predict the role of several genes whose functions are currently unknown by using our probabilistic model we can detect false positives of highthroughput data such as yeast twohybrid data in a genomewide experiment we find possible gene regulatory relationships and proteinprotein interactions between large protein complexes that underlie complex regulatory mechanisms of biological processes contact nariaiimsutokyoacjpgenetic loci that regulate inherited traits are routinely identified using quantitative trait locus qtl mapping methods however the genotypephenotype associations do not provide information on the gene expression program through which the genetic loci regulate the traits transcription modules are selfconsistent regulatory units and are closely related to the modular components of gene regulatory network ihmels j friedlander g bergmann s sarig o ziv y and barkai n 2002 revealing modular organization in the yeast transcriptional network nat genet 31 370377 segal e shapira m regev a peer d botstein d koller d and friedman n 2003 module networks identifying regulatory modules and their conditionspecific regulators from gene expression data nat genet 34 166176 we used genomewide genotype and gene expression data of a genetic reference population that consists of mice of 32 recombinant inbred strains to identify the transcription modules and the genetic loci regulating them twentynine transcription modules defined by genetic variations were identified statistically significant associations between the transcription modules and 18 classical physiological and behavioral traits were found genomewide interval mapping showed that major qtls regulating the transcription modules are often colocalized with the qtls regulating the associated classical traits the association and the possible coregulation of the classical trait and transcription module indicate that the transcription module may be involved in the gene pathways connecting the qtl and the classical trait our results show that a transcription module may associate with multiple seemingly unrelated classical traits and a classical trait may associate with different modules literature mining results provided strong independent evidences for the relations among genes of the transcription modules genes in the regions of the qtls regulating the transcription modules and the keywords representing the classical traitsa central problem in the bioinformatics of gene regulation is to find the binding sites for regulatory proteins one of the most promising approaches toward identifying these short and fuzzy sequence patterns is the comparative analysis of orthologous intergenic regions of related species this analysis is complicated by various factors first one needs to take the phylogenetic relationship between the species into account in order to distinguish conservation that is due to the occurrence of functional sites from spurious conservation that is due to evolutionary proximity second one has to deal with the complexities of multiple alignments of orthologous intergenic regions and one has to consider the possibility that functional sites may occur outside of conserved segments here we present a new motif sampling algorithm phylogibbs that runs on arbitrary collections of multiple local sequence alignments of orthologous sequences the algorithm searches over all ways in which an arbitrary number of binding sites for an arbitrary number of transcription factors tfs can be assigned to the multiple sequence alignments these binding site configurations are scored by a bayesian probabilistic model that treats aligned sequences by a model for the evolution of binding sites and  ” background” intergenic dna this model takes the phylogenetic relationship between the species in the alignment explicitly into account the algorithm uses simulated annealing and monte carlo markovchain sampling to rigorously assign posterior probabilities to all the binding sites that it reports in tests on synthetic data and real data from five saccharomyces species our algorithm performs significantly better than four other motiffinding algorithms including algorithms that also take phylogeny into account our results also show that in contrast to the other algorithms phylogibbs can make realistic estimates of the reliability of its predictions our tests suggest that running on the fivespecies multiple alignment of a single genes upstream region phylogibbs on average recovers over 50 of all binding sites in s cerevisiae at a specificity of about 50 and 33 of all binding sites at a specificity of about 85 we also tested phylogibbs on collections of multiple alignments of intergenic regions that were recently annotated based on chiponchip data to contain binding sites for the same tf we compared phylogibbss results with the previous analysis of these data using six other motiffinding algorithms for 16 of 21 tfs for which all other motiffinding methods failed to find a significant motif phylogibbs did recover a motif that matches the literature consensus in 11 cases where there was disagreement in the results we compiled lists of known target genes from the literature and found that running phylogibbs on their regulatory regions yielded a binding motif matching the literature consensus in all but one of the cases interestingly these literature gene lists had little overlap with the targets annotated based on the chiponchip data the phylogibbs code can be downloaded from httpwwwbiozentrumunibaschnimwege\\u200bncgibinphylogibbscgi or httpwwwimscresinrsiddphylogibbs the full set of predicted sites from our tests on yeast are available at httpwwwswissregulonunibasch computational discovery of regulatory sites in intergenic dna is one of the central problems in bioinformatics up until recently motif finders would typically take one of the following two general approaches given a known set of coregulated genes one searches their promoter regions for significantly overrepresented sequence motifs alternatively in a  ” phylogenetic footprinting” approach one searches multiple alignments of orthologous intergenic regions for short segments that are significantly more conserved than expected based on the phylogeny of the species in this work the authors present an algorithm phylogibbs that combines these two approaches into one integrated bayesian framework the algorithm searches over all ways in which an arbitrary number of binding sites for an arbitrary number of transcription factors can be assigned to arbitrary collections of multiple sequence alignments while taking into account the phylogenetic relations between the sequences the authors perform a number of tests on synthetic data and real data from saccharomyces genomes in which phylogibbs significantly outperforms other existing methods finally a novel annealandtrack strategy allows phylogibbs to make accurate estimates of the reliability of its predictionsmachine learning was applied for the automated derivation of causal influences in cellular signaling networks this derivation relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells perturbing these cells with molecular interventions drove the ordering of connections between pathway components wherein bayesian network computational methods automatically elucidated most of the traditionally reported signaling relationships and predicted novel interpathway network causalities which we verified experimentally reconstruction of network models from physiologically relevant primary single cells might be applied to understanding nativestate tissue signaling biology complex drug actions and dysfunctional signaling in diseased cellsmotivation micrornas mirnas are small endogenous rnas that can play important regulatory roles via the rnainterference pathway by targeting mrnas for cleavage or translational repression we propose a computational method to predict mirna regulatory modules mrms or groups of mirnas and target genes that are believed to participate cooperatively in posttranscriptional gene regulation results we tested our method with the human genes and mirnas predicting 431 mrms we analyze a module with genes btg2 wt1 ppm1d pak7 and rab9b and mirnas mir15a and mir16 review of the literature and annotation with gene ontology terms reveal that the roles of these genes can indeed be closely related in specific biological processes such as gene regulation involved in breast renal and prostate cancers furthermore it has been reported that mir15a and mir16 are deleted together in certain types of cancer suggesting a possible connection between these mirnas and cancers given that most known functionalities of mirnas are related to negative gene regulation extending our approach and exploiting the insight thus obtained may provide clues to achieving practical accuracy in the reverseengineering of gene regulatory networks availability a list of predicted modules is available from the authors upon requestthousands of mammalian messenger rnas are under selective pressure to maintain 7nucleotide sites matching micrornas mirnas we found that these conserved targets are often highly expressed at developmental stages before mirna expression and that their levels tend to fall as the mirna that targets them begins to accumulate nonconserved sites which outnumber the conserved sites 10 to 1 also mediate repression as a consequence genes preferentially expressed at the same time and place as a mirna have evolved to selectively avoid sites matching the mirna this phenomenon of selective avoidance extends to thousands of genes and enables spatial and temporal specificities of mirnas to be revealed by finding tissues and developmental stages in which messages with corresponding sites are expressed at lower levelsgene expression variation has been the focus of many studies in the past few years the relevance of gene regulation and gene expression to disease and the development of the technologies used to screen large numbers of genes simultaneously have allowed this rapid development in this review we discuss issues relating to the biological information one obtains from such studies and the biological significance and use of signals from mapping of gene expression variation')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuations to make the text clear and can be split on ' '\n",
    "def lower_clean_str(x):\n",
    "  punc='!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_`{|}~-'\n",
    "  lowercased_str = x[1].lower()\n",
    "  for ch in punc:\n",
    "    lowercased_str = lowercased_str.replace(ch, '')\n",
    "  return x[0], lowercased_str\n",
    "\n",
    "punc = grouped.map(lower_clean_str)\n",
    "\n",
    "punc.take(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating Combiner, to use it as combineByKey\n",
    "createCombiner = (lambda el: [el]) \n",
    "mergeVal = (lambda aggregated, el: aggregated + [el]) # append to aggregated\n",
    "mergeComb = (lambda agg1,agg2: agg1 + agg2 )  # append agg1 with agg2\n",
    "\n",
    "# Counting words and Combining then using key.\n",
    "new = punc.map(lambda x: [((x[0], a), 1) for a in x[1].split(' ')]).flatMap(lambda l : l).reduceByKey(add)\\\n",
    "        .filter(lambda x: x[0][1] not in broadcastVar.value).sortBy(lambda x: x[1], False)\\\n",
    "        .map(lambda x: (x[0][0], x[0][1])).combineByKey(cComb,mVal,mComb)\n",
    "rdd_new = new.map(lambda x: (x[0], x[1][0:10]))\n",
    "rdd_new.take(2)\n",
    "print(\"Time: \", end-start )\n",
    "\n",
    "# 2750.50794 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing RDD to file\n",
    "rdd_new.coalesce(1).saveAsTextFile(\"Result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.4: Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28416\n",
      "172079\n",
      "828481\n"
     ]
    }
   ],
   "source": [
    "# No. of Distinct Users\n",
    "d_users = userRatingsRDD.countByKey()\n",
    "total_users = sum(y for x, y in d_users.items())\n",
    "print(total_users)\n",
    "\n",
    "#28416\n",
    "\n",
    "# No. of Distinct Items\n",
    "d_items = paperTermsRDD.countByKey()\n",
    "total_items = sum(y for x, y in d_items.items())\n",
    "print(total_items)\n",
    "\n",
    "#172079\n",
    "\n",
    "# No. of Ratings\n",
    "ratings = exploded.countByValue()\n",
    "total_ratings = sum(y for x,y in ratings.items())\n",
    "print(total_ratings)\n",
    "\n",
    "#828481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum:  1\n",
      "Maximum:  1922\n"
     ]
    }
   ],
   "source": [
    "# Minimum Rating Given by a user: userhash ratings.\n",
    "ratings = exploded.countByKey()\n",
    "ratings = ratings.values()\n",
    "\n",
    "mini = min(ratings)\n",
    "print(\"Minimum: \", mini)\n",
    "\n",
    "#Minimum: 1\n",
    "\n",
    "maxx = max(ratings)\n",
    "print(\"Maximum: \", maxx)\n",
    "#Maximum: 1922"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average:  29.155440596846848\n"
     ]
    }
   ],
   "source": [
    "# Average number ratings of users: For it we will use total ratings/distinct_users we calculated earlier.\n",
    "avg_rating = total_ratings/total_users\n",
    "print(\"Average: \", avg_rating)\n",
    "#Average:  29.155440596846848\n",
    "\n",
    "#Standard Deviation:\n",
    "#stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum:  3\n",
      "Maximum:  924\n",
      "Average:  4.81453867119172\n"
     ]
    }
   ],
   "source": [
    "# Minimum number of Ratings an item has received.\n",
    "# CountByValue giving IOPub data rate exceeded Error.\n",
    "# Therefore using reversed_ rdd and countByKey.\n",
    "ratings_ = reversed_.countByKey()\n",
    "ratings_ = ratings_.values()\n",
    "\n",
    "min_rat = min(ratings_)\n",
    "print(\"Minimum: \", min_rat)\n",
    "\n",
    "#Minimum: 3\n",
    "max_rat = max(ratings_)\n",
    "print(\"Maximum: \", max_rat)\n",
    "\n",
    "#Maximum: 924\n",
    "\n",
    "#Average no. of ratings of Items, for This we will use total_ratings/total_items\n",
    "avg_rat_item = total_ratings/total_items\n",
    "print(\"Average: \", avg_rat_item)\n",
    "\n",
    "#Average: 4.81453867119172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.5 DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User: string (nullable = true)\n",
      " |-- Papers_ID: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using two columns as StringType (Later will assign second column (Papers_ID) to array.)\n",
    "schema = StructType([\n",
    "    StructField(\"User\", StringType(), False),\n",
    "    StructField(\"Papers_ID\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Creating DataFrame df for users_libraries\n",
    "userDF = sqlC.read.schema(schema)\\\n",
    "        .option(\"header\", 'False').option(\"delimiter\", \";\").csv(\"users_libraries.txt\")\n",
    "\n",
    "\n",
    "#userDF.show(10, False)\n",
    "userDF.printSchema()\n",
    "#userDF.show(20, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating Papers.csv DataFrame\n",
    "# I didnt create schema for this DF, because at the end i needed two columns and wanted to change\n",
    "# type of only paper_id column to IntegerType()\n",
    "paperDF = sqlC.read.csv(\"papers.csv\")\n",
    "columns= [\"paper_id\", \"type\", \"journal\", \"bookـtitle\", \"series\", \"publisher\", \"pages\", \"volume\", \"number\", \"year\", \"month\", \"postedat\",\"address\",\"title\", \"abstract\"]\n",
    "oldCols = paperDF.schema.names\n",
    "for i, x in enumerate(oldCols):\n",
    "    paperDF = paperDF.withColumnRenamed(x, columns[i])\n",
    "paperDF.show(2)\n",
    "paperDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.3 with DataFrames ( Joining Collections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Type casting from str to array so i can apply explode function on papers_id column.\n",
    "def str_to_arr(my_list):\n",
    "    my_list = my_list.split(\",\")\n",
    "    return [x for x in my_list]\n",
    "\n",
    "str_to_arr_udf = udf(str_to_arr,ArrayType(StringType()))\n",
    "\n",
    "userDF = userDF.withColumn('PapersID',str_to_arr_udf(userDF[\"Papers_ID\"]))\n",
    "userDF = userDF.drop(\"Papers_ID\")\n",
    "userDF.show(2, False)\n",
    "userDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+\n",
      "|User                            |Paper_ID|\n",
      "+--------------------------------+--------+\n",
      "|28d3f81251d94b09735497477a5e4e02|3929762 |\n",
      "|28d3f81251d94b09735497477a5e4e02|503574  |\n",
      "+--------------------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking if explode function is working properly\n",
    "userDF2 = userDF.select(userDF.User, sf.explode(userDF.PapersID))\n",
    "userDF2 = userDF2.withColumn(\"Paper_ID\", userDF2[\"col\"])\n",
    "userDF2 = userDF2.drop(\"col\")\n",
    "userDF2.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- paper_id: integer (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- journal: string (nullable = true)\n",
      " |-- bookـtitle: string (nullable = true)\n",
      " |-- series: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- pages: string (nullable = true)\n",
      " |-- volume: string (nullable = true)\n",
      " |-- number: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- postedat: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- abstract: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Changing datatype of paper_id to IntegerType()\n",
    "paperDF = paperDF.withColumn(\"paper_id\", col(\"paper_id\").cast(IntegerType()))\n",
    "paperDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|paper_id|            abstract|\n",
      "+--------+--------------------+\n",
      "|   80546|the genetic code ...|\n",
      "| 5842862|choosing good pro...|\n",
      "+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Taking subset of Dataset before joining with userDF.\n",
    "papersDF = paperDF[\"paper_id\", \"abstract\"]\n",
    "papersDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|User                            |Paper_ID|paper_id|abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "+--------------------------------+--------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|54daa5d96cafa229a801ba8dd7a24e57|80546   |80546   |the genetic code has been regarded as arbitrary in the sense that the codon-amino acid assignments could be different than they actually are. this general idea has been spelled out differently by previous, often rather implicit accounts of arbitrariness. they have drawn on the frozen accident theory, on evolutionary contingency, on alternative causal pathways, and on the absence of direct stereochemical interactions between codons and amino acids. it has also been suggested that the arbitrariness of the genetic code justifies attributing semantic information to macromolecules, notably to {dna}. i argue that these accounts of arbitrariness are unsatisfactory. i propose that the code is arbitrary in the sense of jacques monod's concept of chemical arbitrariness: the genetic code is arbitrary in that any codon requires certain chemical and structural properties to specify a particular amino acid, but these properties are not required in virtue of a principle of chemistry. this notion of arbitrariness is compatible with several recent hypotheses about code evolution. i maintain that the code's chemical arbitrariness is neither sufficient nor necessary for attributing semantic information to nucleic acids.|\n",
      "|14b532ec70ec6d5ad633792b9c800919|80546   |80546   |the genetic code has been regarded as arbitrary in the sense that the codon-amino acid assignments could be different than they actually are. this general idea has been spelled out differently by previous, often rather implicit accounts of arbitrariness. they have drawn on the frozen accident theory, on evolutionary contingency, on alternative causal pathways, and on the absence of direct stereochemical interactions between codons and amino acids. it has also been suggested that the arbitrariness of the genetic code justifies attributing semantic information to macromolecules, notably to {dna}. i argue that these accounts of arbitrariness are unsatisfactory. i propose that the code is arbitrary in the sense of jacques monod's concept of chemical arbitrariness: the genetic code is arbitrary in that any codon requires certain chemical and structural properties to specify a particular amino acid, but these properties are not required in virtue of a principle of chemistry. this notion of arbitrariness is compatible with several recent hypotheses about code evolution. i maintain that the code's chemical arbitrariness is neither sufficient nor necessary for attributing semantic information to nucleic acids.|\n",
      "+--------------------------------+--------+--------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined = userDF2.join(papersDF, [papersDF.paper_id == userDF2.Paper_ID], \"inner\")\n",
    "joined.show(2, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping PaperID columns as we just need to count words of a user.\n",
    "user_abs = joined.drop(\"paper_id\", \"Paper_ID\")\n",
    "user_abs.show(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.4 with DataFrames ( Basic Analysis )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Users: 28416\n",
      "Distinct Items:  172079\n",
      "Total Ratings:  828481\n"
     ]
    }
   ],
   "source": [
    "#Number of Distinct Users.\n",
    "dist_Users = user_abs.select(user_abs.User).distinct().count()\n",
    "print(\"Distinct Users:\",dist_Users)\n",
    "\n",
    "#Distinct Users: 28416\n",
    "\n",
    "dist_items = papersDF.select(papersDF.paper_id).distinct().count()\n",
    "print(\"Distinct Items: \",dist_items)\n",
    "\n",
    "# Distinct Items: 172079\n",
    "\n",
    "#Total Ratings:\n",
    "total_ratings = user_abs.select(user_abs.abstract).count()\n",
    "print(\"Total Ratings: \", total_ratings)\n",
    "\n",
    "#Total Ratings: 828481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(Count)|\n",
      "+----------+\n",
      "|         1|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(Count)|\n",
      "+----------+\n",
      "|      1922|\n",
      "+----------+\n",
      "\n",
      "+------------------+\n",
      "|        avg(Count)|\n",
      "+------------------+\n",
      "|29.155440596846848|\n",
      "+------------------+\n",
      "\n",
      "+-----------------+\n",
      "|    stddev(Count)|\n",
      "+-----------------+\n",
      "|81.17660451011595|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum number of Ratings a user has given.\n",
    "rat_user = userDF.select(userDF.PapersID).withColumn(\"Count\", size(userDF.PapersID))\n",
    "\n",
    "#Minimum\n",
    "rat_user.agg({\"Count\": 'min'}).show()\n",
    "\n",
    "#Maximum\n",
    "rat_user.agg({\"Count\": 'max'}).show()\n",
    "\n",
    "#Average\n",
    "rat_user.agg({\"Count\": 'avg'}).show()\n",
    "\n",
    "#Std\n",
    "rat_user.agg({\"Count\": 'std'}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|min(Count)|\n",
      "+----------+\n",
      "|         3|\n",
      "+----------+\n",
      "\n",
      "+----------+\n",
      "|max(Count)|\n",
      "+----------+\n",
      "|       924|\n",
      "+----------+\n",
      "\n",
      "+----------------+\n",
      "|      avg(Count)|\n",
      "+----------------+\n",
      "|4.81453867119172|\n",
      "+----------------+\n",
      "\n",
      "+-----------------+\n",
      "|    stddev(Count)|\n",
      "+-----------------+\n",
      "|5.477818208917285|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Minimum rating an Item has received\n",
    "#min_rat_item = userDF2.select(userDF2.Paper_ID).withColumn(\"Count\", )\n",
    "\n",
    "min_rat_items = userDF2.groupBy(\"Paper_ID\").count()\n",
    "\n",
    "#Minimum\n",
    "min_rat_items.agg({\"Count\": 'min'}).show()\n",
    "\n",
    "#Maximum\n",
    "min_rat_items.agg({\"Count\": 'max'}).show()\n",
    "\n",
    "#Average\n",
    "min_rat_items.agg({\"Count\": 'avg'}).show()\n",
    "\n",
    "# Standard Deviation\n",
    "min_rat_items.agg({\"Count\": \"std\"}).show()\n",
    "#5.477818208917285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tryy = userRatingsRDD.take(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sqlC.createDataFrame(tryy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  _1|                  _2|\n",
      "+--------------------+--------------------+\n",
      "|f05bcffe7951de9e5...|[1158654, 478707,...|\n",
      "|28d3f81251d94b097...|[3929762, 503574,...|\n",
      "|d0c9aaa788153daea...|[2080631, 6343346...|\n",
      "|ca4f1ba4094011d9a...|            [278019]|\n",
      "|d1d41a15201915503...|[6610569, 6493797...|\n",
      "|f2f77383828ea6d39...|[943458, 238121, ...|\n",
      "|9c883d02115400f7b...|[3509971, 3509965...|\n",
      "|b656009a6efdc8b1a...|[771870, 181369, ...|\n",
      "|cf9c7f356092c34be...|             [90558]|\n",
      "|0f5cbb39410a9278f...|           [9344598]|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
